import cv2
import mediapipe as mp
import numpy as np


def test_mediapipe():
    print("üß™ Testing MediaPipe for person detection...")

    # Initialize MediaPipe
    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    # Test with webcam
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("‚ùå Cannot open webcam")
        # Try alternative webcam index
        cap = cv2.VideoCapture(1)
        if not cap.isOpened():
            print("‚ùå No webcam found")
            return

    print("‚úÖ Webcam opened. Press 'q' to quit.")

    with mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5) as pose:

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # Convert BGR to RGB
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False

            # Process the image
            results = pose.process(image)

            # Convert back to BGR
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

            # Draw pose landmarks and bounding box
            if results.pose_landmarks:
                # Draw pose landmarks (skeleton)
                mp_drawing.draw_landmarks(
                    image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                    mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2)
                )

                # Get bounding box from landmarks
                h, w, _ = image.shape
                landmarks = results.pose_landmarks.landmark

                # Extract all x and y coordinates
                x_coords = [lm.x * w for lm in landmarks]
                y_coords = [lm.y * h for lm in landmarks]

                # Calculate bounding box with some padding
                x_min, x_max = int(min(x_coords)), int(max(x_coords))
                y_min, y_max = int(min(y_coords)), int(max(y_coords))

                # Add padding
                padding = 20
                x_min = max(0, x_min - padding)
                y_min = max(0, y_min - padding)
                x_max = min(w, x_max + padding)
                y_max = min(h, y_max + padding)

                # Draw bounding box
                cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 3)
                cv2.putText(image, 'PERSON DETECTED', (x_min, y_min - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                # Draw center point
                center_x = (x_min + x_max) // 2
                center_y = (y_min + y_max) // 2
                cv2.circle(image, (center_x, center_y), 5, (0, 0, 255), -1)

            # Display frame
            cv2.imshow('MediaPipe Person Detection - Press Q to quit', image)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    cap.release()
    cv2.destroyAllWindows()
    print("‚úÖ MediaPipe test completed successfully!")


if __name__ == "__main__":
    test_mediapipe()